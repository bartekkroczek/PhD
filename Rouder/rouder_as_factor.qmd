---
title: "rouder_analizy"
format: html
---

## Mine 


```{r}
# Load libraries
library(tidyverse)
library(fs)
library(patchwork)
library(lavaan)
library(ggplot2)
library(psych)
library(corrplot)
```
```{r}
legal_ids <- c("Y2-S2-002K25", "Y2-S2-003K22", "Y2-S2-004K21", "Y2-S2-008K23",
  "Y2-S2-009K22", "Y2-S2-010K21", "Y2-S2-011K24", "Y2-S2-012M26", 
  "Y2-S2-013M31", "Y2-S2-014K21", "Y2-S2-015K27", "Y2-S2-017K23",
  "Y2-S2-018K21", "Y2-S2-019K19", "Y2-S2-020K19", "Y2-S2-021M22",
  "Y2-S2-022M27", "Y2-S2-024M20", "Y2-S2-025K21", "Y2-S2-026K24",
  "Y2-S2-027K22", "Y2-S2-028K24", "Y2-S2-029M24", "Y2-S2-030K23",
  "Y2-S2-033K24", "Y2-S2-034K26", "Y2-S2-035K29", "Y2-S2-037K20",
  "Y2-S2-045K30", "Y2-S2-047M32", "Y2-S2-049K21", "Y2-S2-051K23",
  "Y2-S2-053K19", "Y2-S2-054K22", "Y2-S2-055K22", "Y2-S2-056M23",
  "Y2-S2-058K25", "Y2-S2-062M21", "Y2-S2-065K21", "Y2-S2-068K20",
  "Y2-S2-069K23", "Y2-S2-070K25", "Y2-S2-071K29", "Y2-S2-072M23",
  "Y2-S2-074M24", "Y2-S2-076K22", "Y2-S2-077K20", "Y2-S2-078M27",
  "Y2-S2-080K20", "Y2-S2-081K20", "Y2-S2-082K20", "Y2-S2-084K38",
  "Y2-S2-088K19", "Y2-S2-090M19", "Y2-S2-092M28", "Y2-S2-094K22",
  "Y2-S2-095M27", "Y2-S2-096K22", "Y2-S2-100K21", "Y2-S2-102M22",
  "Y2-S2-104K22", "Y2-S2-107K21", "Y2-S2-108M20", "Y2-S2-109K20",
  "Y2-S2-111K20", "Y2-S2-112M21", "Y2-S2-113K19", "Y2-S2-114K19",
  "Y2-S2-118K19", "Y2-S2-119K21", "Y2-S2-120K25", "Y2-S2-121M22",
  "Y2-S2-122K22", "Y2-S2-123M22", "Y2-S2-127K20", "Y2-S2-129K31",
  "Y2-S2-130K21", "Y2-S2-131M23", "Y2-S2-132M21", "Y2-S2-133K20",
  "Y2-S2-134M23", "Y2-S2-135K23", "Y2-S2-137K20", "Y2-S2-138K24",
  "Y2-S2-140K31", "Y2-S2-141K21", "Y2-S2-142K23", "Y2-S2-144M20",
  "Y2-S2-146K21", "Y2-S2-147K19", "Y2-S2-148K21", "Y2-S2-149K18",
  "Y2-S2-150K21", "Y2-S2-152M20", "Y2-S2-153K20", "Y2-S2-154K24",
  "Y2-S2-156K20", "Y2-S2-158K20", "Y2-S2-159K18", "Y2-S2-160K20",
  "Y2-S2-161K21", "Y2-S2-164K18", "Y2-S2-166K18", "Y2-S2-169M21",
  "Y2-S2-170K23", "Y2-S2-171K21", "Y2-S2-175K21", "Y2-S2-176M26",
  "Y2-S2-179K21", "Y2-S2-181K21", "Y2-S2-183K22", "Y2-S2-184K25",
  "Y2-S2-186K19", "Y2-S2-187M32", "Y2-S2-188M25", "Y2-S2-189K21",
  "Y2-S2-190K21", "Y2-S2-191K20", "Y2-S2-193K20", "Y2-S2-194K21",
  "Y2-S2-195K21", "Y2-S2-197K23", "Y2-S2-198K23", "Y2-S2-200K18",
  "Y2-S2-202K23", "Y2-S2-203K22", "Y2-S2-206K20", "Y2-S2-207M23",
  "Y2-S2-208K19", "Y2-S2-208K26", "Y2-S2-211M23", "Y2-S2-212K24",
  "Y2-S2-213K23", "Y2-S2-214K21", "Y2-S2-215M19", "Y2-S2-216K24",
  "Y2-S2-220M19", "Y2-S2-224K20", "Y2-S2-228M20", "Y2-S2-229K21",
  "Y2-S2-230K20", "Y2-S2-231K22", "Y2-S2-232K20", "Y2-S2-233K19",
  "Y2-S2-234K20", "Y2-S2-240K20", "Y2-S2-242K22", "Y2-S2-244K18",
  "Y2-S2-247K19", "Y2-S2-250K25", "Y2-S2-251M22", "Y2-S2-253M20",
  "Y2-S2-257K25", "Y2-S2-260K19", "Y2-S2-261K24", "Y2-S2-262K26",
  "Y2-S2-265K19", "Y2-S2-266K22", "Y2-S2-267K23", "Y2-S2-268M21",
  "Y2-S2-269K20", "Y2-S2-270K21", "Y2-S2-273K18", "Y2-S2-274K23",
  "Y2-S2-276K20", "Y2-S2-278K20", "Y2-S2-280M21", "Y2-S2-281K22",
  "Y2-S2-282M23", "Y2-S2-283K20", "Y2-S2-284K20", "Y2-S2-285M22", 
  "Y2-S2-286K22", "Y2-S2-287M23")

length(legal_ids)
```


```{r}
create_saccade_plots <- function(df, cors, contrast, y_lab) {
  library(ggplot2)
  library(patchwork)
  
  p1 <- ggplot(df, aes(x = pro, y = anti)) +
    geom_point(color = scales::alpha("blue", 0.3), size = 3) +
    geom_smooth(method = "lm", se = TRUE, linetype = 2, color = "black") +
    annotate("text", x = mean(df$pro), y = max(df$anti) * 0.9, label = paste0("R = ", cors[1,2])) +
    labs(x = "Prosaccade Duration", y = "Antisaccade Duration") +
  #  coord_fixed(ratio = 1, xlim = c(100, 450), ylim = c(175, 625)) +
    theme_minimal() +
    ggtitle("A.")
  
  p2 <- ggplot(df, aes(x = pro, y = .data[[contrast]])) +
    geom_point(color = "blue", size = 3, alpha = 0.3) +
    geom_smooth(method = "lm", se = TRUE, linetype = 2, color = "black") +
    annotate("text", x = mean(df$pro), y = max(df[[contrast]] * 0.9), label = paste0("R = ", cors[1,3])) +
    labs(x = "Prosaccade Duration", y = y_lab) +
   # coord_cartesian(xlim = c(100, 450), ylim = c(0, 250)) +
    theme_minimal() +
    ggtitle("B.")
  
  p3 <- ggplot(df, aes(x = anti, y = .data[[contrast]])) +
    geom_point(color = "blue", size = 3, alpha = 0.3) +
    geom_smooth(method = "lm", se = TRUE, linetype = 2, color = "black") +
    annotate("text", x = mean(df$anti), y = max(df[[contrast]] * 0.9), label = paste0("R = ", cors[2,3])) +
    labs(x = "Antisaccade Duration", y = y_lab) +
    #coord_cartesian(xlim = c(175, 625), ylim = c(0, 225)) +
    theme_minimal() +
    ggtitle("C.")
  
  return(p1 + p2 + p3 + plot_layout(ncol = 3))
}
```

```{r}
# Load data

files <- dir_ls("data/anti-pro-saccade/beh", glob = "*.csv")

raw_data <- files %>%
  map_df(read_csv, col_types = cols(
    Block_no = col_integer(),
    Block_type = col_character(),
    Trial_no = col_integer(),
    CSI = col_integer(),
    Level = col_integer(),
    Reversal = col_integer(),
    Revs_count = col_integer()
  )) 
glimpse(raw_data)
```


```{r}
# This value can be obtained from a last reversal in each block.
meaningful_revs_count <- 10

clean_data <- raw_data |>
  filter(PART_ID %in% legal_ids) |>
  filter(Revs_count > meaningful_revs_count, Reversal == 1) |>
  select(PART_ID, Block_no, Block_type, `Stimulus Time`, Revs_count) |>
  group_by(PART_ID, Block_no) |>
  summarise(duration_ms = mean(`Stimulus Time`)  * (1000 / 60), 
            Block_type = first(Block_type), 
            .groups = "drop") 
```


# By block FACTOR analiysis

```{r}
block_for_factors <- clean_data |> 
  select(-Block_no) |>
  group_by(PART_ID, Block_type) |>
  mutate(Block_order = row_number()) |> 
  ungroup() |>
  pivot_wider(
    names_from = c("Block_type", "Block_order"), 
    values_from = duration_ms, 
    names_sep = "_") 
head(block_for_factors)
```

```{r}
# Extract just the numeric variables for analysis
df_numeric <- block_for_factors |> select(starts_with("PS_"))

# 1. Correlation matrix
corr_matrix <- cor(df_numeric)
print(corr_matrix)

# 2. KMO and Bartlett's Test (sampling adequacy)
KMO(df_numeric)
cortest.bartlett(df_numeric)
```


```{r}
# 3. Determine number of factors
fa.parallel(df_numeric, fa = "fa")

# 4. Quick EFA to check if one-factor solution is reasonable
efa_result <- fa(df_numeric, nfactors = 1)
print(efa_result$loadings)
print(efa_result$communality)  # Variance explained per variable
```


```{r}
as_model <- '
  anti =~ AS_1 + AS_2 + AS_3 + AS_4
  anti ~~ 1*anti
'
ps_model <- '
  pro =~ PS_1 + PS_2 + PS_3 + PS_4
  pro ~~ 1*pro
'

# Fit the CFA models
fit_as <- cfa(as_model, data = block_for_factors)
fit_ps <- cfa(ps_model, data = block_for_factors)

# Extract fit indices for reporting
fit_indices_as <- fitMeasures(fit_as, c("cfi", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper"))
fit_indices_ps <- fitMeasures(fit_ps, c("cfi", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper"))

# Print fit indices for easy reporting
cat("Anti-saccade model fit:\n")
cat(sprintf("CFI = %.3f, RMSEA = %.3f [90%% CI: %.3f, %.3f]\n", 
            fit_indices_as["cfi"], 
            fit_indices_as["rmsea"], 
            fit_indices_as["rmsea.ci.lower"], 
            fit_indices_as["rmsea.ci.upper"]))

cat("\nPro-saccade model fit:\n")
cat(sprintf("CFI = %.3f, RMSEA = %.3f [90%% CI: %.3f, %.3f]\n", 
            fit_indices_ps["cfi"], 
            fit_indices_ps["rmsea"], 
            fit_indices_ps["rmsea.ci.lower"], 
            fit_indices_ps["rmsea.ci.upper"]))

# Extract factor scores
factor_scores_as <- lavaan::predict(fit_as)
factor_scores_ps <- lavaan::predict(fit_ps)

# Create result dataframe
mean_by_type <- data.frame(
  PART_ID = block_for_factors$PART_ID,
  anti = factor_scores_as,
  pro = factor_scores_ps
) |>
  mutate(diff = anti - pro)
```

```{r}
library(tidyverse)

ggplot(mean_by_type) +
  geom_density(aes(x = pro, fill = "Pro"), alpha = 0.5) +
  geom_density(aes(x = anti, fill = "Anti"), alpha = 0.5) +
  scale_fill_manual(values = c("Pro" = "blue", "Anti" = "red"),
                    name = "Variable") +
  labs(title = "Distribution of Pro and Anti Variables",
       x = "Value",
       y = "Density") +
  theme_minimal()
```


## Processing speed factor


```{r}
temporal_order <- dir_ls("data/Temporal-order/beh", glob = "*.csv")
inspection_time <- dir_ls("data/Inspection-Time/beh", glob = "*.csv")

temporal_order <- temporal_order |>
  map_df(read_csv, col_types = cols(
    Reversal = col_integer(),
    Reversal_count = col_integer()
  ))

inspection_time <- inspection_time |>
  map_df(read_csv, col_types = cols(
     Reversal = col_integer(),
     Reversal_count = col_integer()
   ))

```

```{r}
temporal_order <- temporal_order |>
  filter(PART_ID %in% legal_ids) |>
  filter(Reversal == 1 & Reversal_count > meaningful_revs_count & Training == "exp") |>
  group_by(PART_ID, Stimuli) |>
  summarize(mean_soa = mean(SOA), .groups = "drop") |>
  pivot_wider(
    names_from = Stimuli,
    values_from = mean_soa,
    names_prefix = "temporal_") |> 
  filter(temporal_CIRCLES > 10 & temporal_SQUARES < 10)
```

```{r}
temporal_order |> ggplot(aes(x = temporal_CIRCLES, y = temporal_SQUARES)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, linetype = 2, color = "black") +
  labs(x = "Circles SOA", y = "Squares SOA") +
  theme_minimal()
```

```{r}
inspection_time <- inspection_time |>
  filter(Reversal == 1 & Reversal_count > meaningful_revs_count & Training == "exp") |>
  group_by(PART_ID, Stimuli) |>
  summarize(mean_soa = mean(SOA), .groups = "drop") |>
  pivot_wider(
    names_from = Stimuli,
    values_from = mean_soa,
    names_prefix = "inspection_"
  ) |> filter(inspection_CIRCLES < 15 & inspection_SQUARES < 15)
```

```{r}
inspection_time |> ggplot(aes(x = inspection_CIRCLES, y = inspection_SQUARES)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, linetype = 2, color = "black") +
  labs(x = "Circles SOA", y = "Squares SOA") +
  theme_minimal()
```


```{r}
processing_speed <- inner_join(temporal_order, inspection_time, by = "PART_ID") |> drop_na()

processing_speed <- semi_join(processing_speed, mean_by_type, by = "PART_ID") # only full files
mean_by_type <- semi_join(mean_by_type, processing_speed, by = "PART_ID") # only full files
#processing_speed <- processing_speed |>
#  drop_na()

```



## CFA Preliminary

```{r}
# Extract just the numeric variables for analysis
df_numeric <- processing_speed |> select(-PART_ID)

# 1. Correlation matrix
corr_matrix <- cor(df_numeric)
print(corr_matrix)

# 2. KMO and Bartlett's Test (sampling adequacy)
KMO(df_numeric)
cortest.bartlett(df_numeric)
```


```{r}
# 3. Determine number of factors
fa.parallel(df_numeric, fa = "fa")

# 4. Quick EFA to check if one-factor solution is reasonable
efa_result <- fa(df_numeric, nfactors = 1)
print(efa_result$loadings)
print(efa_result$communality)  # Variance explained per variable
```
- Sample size: CFA typically requires 100+ observations (minimum 5-10 per parameter)
- Adequacy: KMO should be >0.6, Bartlett's test should be significant
- Correlations: Variables should correlate moderately (0.3-0.9)
- Variance explained: The factor should explain substantial variance

## CFA

```{r}
model <- '
  processing_speed =~ temporal_SQUARES + inspection_CIRCLES + inspection_SQUARES
  processing_speed ~~ 1*processing_speed 
'

# Fit the CFA model
fit <- cfa(model, data = processing_speed)

# Extract fit indices for reporting
fit_indices <- fitMeasures(fit, c("cfi", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper"))


# Print fit indices for easy reporting
cat("Model fit:\n")
cat(sprintf("CFI = %.3f, RMSEA = %.3f [90%% CI: %.3f, %.3f]\n", 
            fit_indices["cfi"], 
            fit_indices["rmsea"], 
            fit_indices["rmsea.ci.lower"], 
            fit_indices["rmsea.ci.upper"]))

# Extract factor scores
factor_scores <- lavaan::predict(fit)

# # Scale factor scores to 0-1 range using min-max normalization
# min_score <- min(factor_scores)
# max_score <- max(factor_scores)
# normalized_scores <- (factor_scores - min_score) / (max_score - min_score)

# Create result dataframe
processing_speed_df <- data.frame(
  PART_ID = processing_speed$PART_ID,
  processing_speed = factor_scores
)

```

```{r}
df <- inner_join(mean_by_type, processing_speed_df, by = "PART_ID")
```
```{r}
anti_join(mean_by_type, processing_speed_df, by = "PART_ID")
```
```{r}
head(df)
```

## Question: Should I remove factors with values above 3 

```{r}
df |> filter(abs(pro) > 3 | abs(anti) > 3 | abs(processing_speed) > 3 |  abs(diff) > 3)
```


```{r}
tmp_df <- df |> filter(abs(pro) < 3, abs(anti) < 3, abs(processing_speed) < 3,  abs(diff) < 3)
# tmp_df <- df
```


## Results 


```{r}
cors <- tmp_df |>
  select(pro, anti, diff) |>
  cor() |>
  round(2)

create_saccade_plots(tmp_df, cors, contrast = "diff", y_lab = "Antisaccade - Prosaccade")
```


```{r}
# Calculate correlations

cors <- tmp_df |>
  select(pro, anti, processing_speed) |>
  cor() |>
  round(2)

create_saccade_plots(tmp_df, cors, contrast = "processing_speed", y_lab = "Processing Speed")
```





# Is prosaccade in fact a processing speed?

```{r}

ggplot(tmp_df, aes(x = processing_speed, y = pro)) +
    geom_point(color = "blue", size = 3, alpha = 0.3) +
    geom_smooth(method = "lm", se = TRUE, linetype = 2, color = "black") +
    annotate("text", x = mean(tmp_df$processing_speed), y = max(tmp_df$pro) * 0.9, label = paste0("R = ", round(cor(tmp_df$processing_speed, tmp_df$pro), 2))) +
    labs(x = "Processing Speed", y = "Prosacade") +
   #  coord_cartesian(xlim = c(100, 450), ylim = c(0, 250)) +
    theme_minimal()
```

# Is cognitive control in fact a processing speed?

```{r}

ggplot(tmp_df, aes(x = processing_speed, y = diff)) +
    geom_point(color = "blue", size = 3, alpha = 0.3) +
    geom_smooth(method = "lm", se = TRUE, linetype = 2, color = "black") +
    annotate("text", x = mean(tmp_df$processing_speed), y = max(tmp_df$diff) * 0.9, label = paste0("R = ", round(cor(tmp_df$processing_speed, tmp_df$diff), 2))) +
    labs(x = "Processing Speed", y = "Antisaccade - Prosacade") +
   #  coord_cartesian(xlim = c(100, 450), ylim = c(0, 250)) +
    theme_minimal()
```









